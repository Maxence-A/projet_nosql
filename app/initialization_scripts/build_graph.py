"""
Script optimis√© pour construire le graphe Neo4j √† partir des donn√©es MongoDB
en utilisant la librairie Graph Data Science (GDS) pour le calcul de similarit√©.
"""

import os
from pymongo import MongoClient
from neo4j import GraphDatabase

# ---------------------------
# CONFIG MONGO / NEO4J
# ---------------------------

MONGO_URI = os.environ.get("MONGO_URI", "mongodb://mongo:27017") 
DB_NAME = "protein_db"
COLLECTION_NAME = "all_proteins"

NEO4J_URI = os.environ.get("NEO4J_URI", "bolt://neo4j:7687")
NEO4J_USER = os.environ.get("NEO4J_USER", "neo4j")
NEO4J_PASSWORD = os.environ.get("NEO4J_PASSWORD", "password")

# Seuils
MIN_JACCARD_WEIGHT = 0.1 
GRAPH_NAME = "protein_domain_graph"
RELATIONSHIP_TYPE = "SIMILAR"
IMPORT_BATCH_SIZE = 2500  

def import_proteins_and_domains(col, driver):
    """
    1) Cr√©e les n≈ìuds Protein et Domain
    2) Cr√©e les relations HAS_DOMAIN
    √† partir de la collection Mongo.
    """
    # On r√©cup√®re toutes les prot√©ines
    cursor = col.find({}, projection={
        "_id": 1,
        "uniprot_id": 1,
        "entry_name": 1,
        "organism": 1,
        "sequence.aa": 1,
        "sequence.length": 1,
        "ec_numbers": 1,
        "interpro_ids": 1,
        "is_labelled": 1,
    })

    with driver.session() as session:
        # Cr√©ation des contraintes (Index uniques)
        print("üîí V√©rification des contraintes Neo4j...")
        session.run("CREATE CONSTRAINT IF NOT EXISTS FOR (p:Protein) REQUIRE p.uniprot_id IS UNIQUE")
        session.run("CREATE CONSTRAINT IF NOT EXISTS FOR (d:Domain) REQUIRE d.interpro_id IS UNIQUE")
        # Index secondaire pour recherche rapide
        session.run("CREATE INDEX IF NOT EXISTS FOR (p:Protein) ON (p.organism)")

        batch = []
        total_processed = 0

        for doc in cursor:
            uniprot_id = doc.get("uniprot_id") or doc.get("_id")
            if not uniprot_id:
                continue

            entry_name = doc.get("entry_name")
            organism = doc.get("organism")
            length = doc.get("sequence", {}).get("length")
            ec_numbers = doc.get("ec_numbers", [])
            is_labelled = bool(doc.get("is_labelled", False))
            interpro_ids = doc.get("interpro_ids", [])

            batch.append({
                "uniprot_id": uniprot_id,
                "entry_name": entry_name,
                "organism": organism,
                "length": length,
                "ec_numbers": ec_numbers,
                "is_labelled": is_labelled,
                "interpro_ids": interpro_ids,
            })

            if len(batch) >= IMPORT_BATCH_SIZE:
                import_batch(session, batch)
                total_processed += len(batch)
                print(f"   Import√© {total_processed} prot√©ines...", end="\r")
                batch = []

        if batch:
            import_batch(session, batch)
            total_processed += len(batch)
        
        print(f"\n‚úÖ Import termin√© : {total_processed} prot√©ines dans le graphe.")


def import_batch(session, proteins_batch):
    """
    Import d‚Äôun batch de prot√©ines + leurs domaines dans Neo4j.
    """
    query = """
    UNWIND $rows AS row

    MERGE (p:Protein {uniprot_id: row.uniprot_id})
      SET p.entry_name = row.entry_name,
          p.organism   = row.organism,
          p.length     = row.length,
          p.ec_numbers = row.ec_numbers,
          p.is_labelled = row.is_labelled

    WITH p, row
    UNWIND row.interpro_ids AS interpro_id
      MERGE (d:Domain {interpro_id: interpro_id})
      MERGE (p)-[:HAS_DOMAIN]->(d)
    """
    session.run(query, rows=proteins_batch)


def build_similarity_edges_gds_math(driver):
    """
    Construit les ar√™tes SIMILAR entre prot√©ines en utilisant
    l'algorithme de Similarit√© de N≈ìud (Node Similarity) de GDS,
    bas√© sur le coefficient de Jaccard sur les domaines partag√©s.
    Puis utilise une approche math√©matique pour calculer 'shared_domains' et 'union_domains'.
    """
    print("\n--- D√âBUT DU TRAITEMENT SIMILARIT√â (GDS + MATH) ---")
    
    # 1. Nettoyage
    clean_previous_data(driver)
    
    # 2. Projection
    project_graph(driver)
    
    # 3. Calcul de similarit√© (Cr√©ation des ar√™tes)
    run_gds_similarity(driver, threshold=MIN_JACCARD_WEIGHT)
    
    # 4. Nettoyage m√©moire GDS 
    drop_graph_projection(driver)
    
    # 5. Pr√©paration des donn√©es pour la formule math√©matique
    precalculate_domain_counts(driver)
    
    # 6. Mise √† jour des propri√©t√©s "shared_domains" et "union_domains" via la formule math√©matique
    calculate_shared_union_domains_math(driver)
    
    print("--- TRAITEMENT TERMIN√â ---\n")

def clean_previous_data(driver):
    """√âtape 1 : Nettoie les anciennes relations et la projection GDS si elle existe."""

    print("1) Nettoyage des anciennes relations et projections...")

    with driver.session() as session:
        # Suppression s√©curis√©e des relations par lots
        session.run(f"""
        CALL apoc.periodic.iterate(
            'MATCH ()-[r:{RELATIONSHIP_TYPE}]-() RETURN r',
            'DELETE r',
            {{batchSize: 50000, parallel: true}}
        )
        """)
        # Suppression de la projection GDS si elle est rest√©e en m√©moire
        session.run(f"""
        CALL gds.graph.exists('{GRAPH_NAME}') YIELD exists
        WITH exists WHERE exists
        CALL gds.graph.drop('{GRAPH_NAME}') YIELD graphName
        RETURN graphName
        """)

def project_graph(driver):
    """√âtape 2 : Projette le graphe en m√©moire pour GDS."""

    print("2) Projection du graphe GDS...")

    query = f"""
    CALL gds.graph.project(
        '{GRAPH_NAME}',
        ['Protein', 'Domain'],
        'HAS_DOMAIN'
    )
    YIELD graphName, nodeCount, relationshipCount
    """
    with driver.session() as session:
        result = session.run(query)
        summary = result.single()
        if summary:
            print(f"  - Graphe projet√© : {summary['nodeCount']} n≈ìuds, {summary['relationshipCount']} relations.")
        else:
            raise Exception("√âchec de la projection du graphe GDS.")
    
def run_gds_similarity(driver, threshold):
    """√âtape 3 : Ex√©cute l'algo Node Similarity (Jaccard) de GDS."""

    print(f"3) Calcul GDS (Jaccard > {threshold})...")

    query = f"""
    CALL gds.nodeSimilarity.write(
        '{GRAPH_NAME}',
        {{
            similarityMetric: 'JACCARD',
            writeRelationshipType: '{RELATIONSHIP_TYPE}',
            writeProperty: 'jaccard_weight',
            similarityCutoff: {threshold},
            concurrency: 4
        }}
    )
    YIELD nodesCompared, relationshipsWritten
    """
    with driver.session() as session:
        result = session.run(query)
        summary = result.single()
        print(f"  - GDS termin√© : {summary['relationshipsWritten']} relations cr√©√©es.")

def drop_graph_projection(driver):
    """√âtape 4 : Lib√®re la m√©moire GDS en supprimant la projection."""

    print("4) Suppression de la projection GDS...")

    with driver.session() as session:
        session.run(f"CALL gds.graph.drop('{GRAPH_NAME}') YIELD graphName")
    
def precalculate_domain_counts(driver):
    """√âtape 5 : Calcule le nombre de domaines par prot√©ine (n√©cessaire pour la m√©thode math√©matique du calcul des propri√©t√©s de SIMILAR)."""

    print("5) Pr√©-calcul du nombre de domaines par prot√©ine...")

    query = """
    CALL apoc.periodic.iterate(
        "MATCH (p:Protein) RETURN p",
        "SET p.domain_count = COUNT { (p)-[:HAS_DOMAIN]->() }",
        {batchSize: 10000, parallel: true}
    )
    """
    with driver.session() as session:
        session.run(query)

def calculate_shared_union_domains_math(driver):
    print("6) üöÄ Calcul final des propri√©t√©s (Math formula)...")
    # Cette requ√™te met √† jour les propri√©t√©s shared_domains et union_domains
    # sans avoir √† refaire des MATCH lourds sur les n≈ìuds Domain.
    query = f"""
    CALL apoc.periodic.iterate(
        "MATCH (p1:Protein)-[r:{RELATIONSHIP_TYPE}]->(p2:Protein) RETURN p1, r, p2",
        "
            WITH p1.domain_count AS A, p2.domain_count AS B, r.jaccard_weight AS J, r
            
            // Math magic: Intersection = (J * (A + B)) / (1 + J)
            WITH A, B, r, toInteger(round((J * (A + B)) / (1.0 + J))) AS intersect
            
            SET r.shared_domains = intersect,
                r.union_domains = (A + B) - intersect
        ",
        {{batchSize: 5000, parallel: true, retries: 3}}
    )
    """
    with driver.session() as session:
        session.run(query)

# --- MAIN ---

if __name__ == "__main__":
    client = MongoClient(MONGO_URI)
    db = client[DB_NAME]
    col = db[COLLECTION_NAME] # "all_proteins"

    # Connexion neo4j
    driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASSWORD))

    try:
        # √âtape 1 : Cr√©ation des n≈ìuds
        import_proteins_and_domains(col, driver)
        
        # √âtape 2 : Cr√©ation des liens de similarit√©
        # Note : On utilise la version 'math' car elle est plus performante pour les gros volumes
        build_similarity_edges_gds_math(driver)
        
    finally:
        driver.close()
        client.close()
        print("üéâ Termin√©.")