"""
Neo4J Requ√™te Module pour la Base de Donn√©es de Graphes de Prot√©ines

Ce module fournit des fonctionnalit√©s compl√®tes de requ√™te pour la base de donn√©es de graphes de prot√©ines.
Il inclut des capacit√©s de recherche, d'exploration de voisinage et des statistiques de graphe.

T√¢ches impl√©ment√©es :
1. Recherche de prot√©ines par identifiant, nom et/ou description
2. Visualisation des voisins des prot√©ines et des voisins des voisins  
3. Calcul des statistiques de graphe (prot√©ines isol√©es, connectivit√©, etc.)
4. Support de visualisation pour les voisinages de prot√©ines
"""

import os
from typing import List, Dict, Any, Optional, Tuple
from neo4j import GraphDatabase, exceptions
import json


class Neo4jProteinQueryManager:
    """Classe gestionnaire pour interroger les donn√©es de graphes de prot√©ines dans Neo4j"""
    
    def __init__(self, neo4j_uri: str = None, user: str = None, password: str = None):
        """
        Initialiser la connexion Neo4j
        
        Args:
            neo4j_uri: Cha√Æne de connexion Neo4j
            user: Nom d'utilisateur Neo4j
            password: Mot de passe Neo4j
        """
        self.neo4j_uri = neo4j_uri or os.environ.get("NEO4J_URI", "bolt://neo4j:7687")
        self.user = user or os.environ.get("NEO4J_USER", "neo4j")
        self.password = password or os.environ.get("NEO4J_PASSWORD", "password")
        self.driver = None
        
    def connect(self):
        """√âtablir la connexion √† Neo4j"""
        try:
            self.driver = GraphDatabase.driver(self.neo4j_uri, auth=(self.user, self.password))
            # Test connection
            with self.driver.session() as session:
                session.run("RETURN 1")
            print(f"‚úÖ Connect√© √† Neo4j √† {self.neo4j_uri}")
        except exceptions.ServiceUnavailable as e:
            print(f"‚ùå Erreur de connexion √† Neo4j : {e}")
            raise
    
    def disconnect(self):
        """Fermer la connexion Neo4j"""
        if self.driver:
            self.driver.close()
            print("üîå D√©connect√© de Neo4j")
    
    def search_by_identifier(self, protein_id: str) -> Optional[Dict[str, Any]]:
        """
        Rechercher une prot√©ine par son identifiant UniProt
        
        Args:
            protein_id: Identifiant UniProt (par exemple, 'P12345')
            
        Returns:
            Propri√©t√©s du n≈ìud prot√©ine ou None si non trouv√©
        """
        query = """
        MATCH (p:Protein {uniprot_id: $protein_id})
        RETURN p
        """
        
        try:
            with self.driver.session() as session:
                result = session.run(query, protein_id=protein_id)
                record = result.single()
                if record:
                    protein_data = dict(record["p"])
                    print(f"‚úÖ Prot√©ine trouv√©e avec l'ID : {protein_id}")
                    return protein_data
                else:
                    print(f"‚ùå Aucune prot√©ine trouv√©e avec l'ID : {protein_id}")
                    return None
        except Exception as e:
            print(f"‚ùå Erreur lors de la recherche par identifiant : {e}")
            return None
    
    def search_by_entry_name(self, search_term: str, case_sensitive: bool = False) -> List[Dict[str, Any]]:
        """
        Rechercher des prot√©ines par nom ou nom d'entr√©e
        
        Args:
            search_term: Terme √† rechercher dans entry_name
            case_sensitive: Indique si la recherche doit √™tre sensible √† la casse
            
        Returns:
            Liste des n≈ìuds prot√©ine correspondants
        """
        if case_sensitive:
            query = """
            MATCH (p:Protein)
            WHERE p.entry_name CONTAINS $search_term
            RETURN p
            ORDER BY p.entry_name
            """
        else:
            query = """
            MATCH (p:Protein)
            WHERE toLower(p.entry_name) CONTAINS toLower($search_term)
            RETURN p
            ORDER BY p.entry_name
            """
        
        try:
            with self.driver.session() as session:
                result = session.run(query, search_term=search_term)
                proteins = [dict(record["p"]) for record in result]
                print(f"‚úÖ {len(proteins)} prot√©ines trouv√©es correspondant √† : '{search_term}'")
                return proteins
        except Exception as e:
            print(f"‚ùå Erreur lors de la recherche par nom : {e}")
            return []
    
    def get_protein_neighborhood(self, protein_id: str, depth: int = 1) -> Dict[str, Any]:
        """
        Obtenir la prot√©ine et son voisinage avec les IDs de source/cible explicites pour les relations.
        """
        # Note : On utilise map projection pour les relations (r {.*, ...}) pour inclure les propri√©t√©s 
        # ET les IDs des n≈ìuds connect√©s dans le m√™me objet.
        
        if depth == 1:
            query = """
            MATCH (p:Protein {uniprot_id: $protein_id})
            OPTIONAL MATCH (p)-[r:SIMILAR]-(neighbor:Protein)
            OPTIONAL MATCH (p)-[r_dom:HAS_DOMAIN]->(d:Domain)
            RETURN p as center_protein,
                   collect(DISTINCT neighbor) as neighbors,
                   collect(DISTINCT r {.*, source: startNode(r).uniprot_id, target: endNode(r).uniprot_id, type: type(r)}) as relationships,
                   collect(DISTINCT d) as domains,
                   collect(DISTINCT r_dom {.*, source: p.uniprot_id, target: d.interpro_id, type: type(r_dom)}) as domain_rels
            """
        else:  # depth = 2
            query = """
            MATCH (p:Protein {uniprot_id: $protein_id})
            // R√©cup√©rer le chemin jusqu'√† la profondeur 2
            OPTIONAL MATCH path = (p)-[:SIMILAR*1..2]-(neighbor:Protein)
            WITH p, collect(path) as paths
            
            // Extraire tous les n≈ìuds et relations uniques des chemins
            WITH p, 
                 apoc.coll.toSet(reduce(nodes = [], path in paths | nodes + nodes(path))) as all_nodes,
                 apoc.coll.toSet(reduce(rels = [], path in paths | rels + relationships(path))) as all_rels
            
            // S√©parer le centre des voisins
            WITH p, 
                 [n in all_nodes WHERE n.uniprot_id <> p.uniprot_id] as neighbors,
                 all_rels
            
            // Ajouter les domaines (uniquement pour le centre pour ne pas surcharger)
            OPTIONAL MATCH (p)-[r_dom:HAS_DOMAIN]->(d:Domain)
            
            RETURN p as center_protein,
                   neighbors,
                   [r in all_rels | r {.*, source: startNode(r).uniprot_id, target: endNode(r).uniprot_id, type: type(r)}] as relationships,
                   collect(DISTINCT d) as domains,
                   collect(DISTINCT r_dom {.*, source: p.uniprot_id, target: d.interpro_id, type: type(r_dom)}) as domain_rels
            """
            # Note: Si APOC n'est pas install√©, la requ√™te depth=2 doit √™tre faite avec des UNWIND standards, 
            # mais la logique ci-dessus est plus propre. Si erreur, me le signaler.

        try:
            with self.driver.session() as session:
                result = session.run(query, protein_id=protein_id)
                record = result.single()
                
                if not record or not record["center_protein"]:
                    print(f"‚ùå Prot√©ine {protein_id} non trouv√©e")
                    return {}
                
                # Fusionner les relations SIMILAR et HAS_DOMAIN
                all_relationships = record["relationships"] + record.get("domain_rels", [])
                
                neighborhood = {
                    "center_protein": dict(record["center_protein"]),
                    "neighbors": [dict(n) for n in record["neighbors"] if n is not None],
                    "relationships": all_relationships, # Ce sont d√©j√† des dicts gr√¢ce √† la projection Cypher
                    "domains": [dict(d) for d in record["domains"] if d is not None],
                    "depth": depth
                }
                
                print(f"‚úÖ Voisinage trouv√© pour {protein_id}")
                return neighborhood
                
        except Exception as e:
            print(f"‚ùå Erreur lors de l'obtention du voisinage : {e}")
            return {}  
    def get_protein_domains(self, protein_id: str) -> List[Dict[str, Any]]:
        """
        Obtenir tous les domaines pour une prot√©ine sp√©cifique
        
        Args:
            protein_id: Identifiant UniProt
            
        Returns:
            Liste des n≈ìuds de domaines connect√©s √† la prot√©ine
        """
        query = """
        MATCH (p:Protein {uniprot_id: $protein_id})-[:HAS_DOMAIN]->(d:Domain)
        RETURN d
        ORDER BY d.interpro_id
        """
        
        try:
            with self.driver.session() as session:
                result = session.run(query, protein_id=protein_id)
                domains = [dict(record["d"]) for record in result]
                print(f"‚úÖ {len(domains)} domaines trouv√©s pour la prot√©ine {protein_id}")
                return domains
        except Exception as e:
            print(f"‚ùå Erreur lors de l'obtention des domaines : {e}")
            return []
    
    def get_statistics(self) -> Dict[str, Any]:
        """
        Calculer des statistiques compl√®tes du graphe
        
        Returns:
            Dictionnaire contenant diverses m√©triques du graphe
        """
        queries = {
            "total_proteins": "MATCH (p:Protein) RETURN count(p) as count",
            "total_domains": "MATCH (d:Domain) RETURN count(d) as count",
            "total_similarities": "MATCH ()-[r:SIMILAR]-() RETURN count(r)/2 as count",
            "labeled_proteins": "MATCH (p:Protein) WHERE p.is_labelled = true RETURN count(p) as count",
            "unlabeled_proteins": "MATCH (p:Protein) WHERE p.is_labelled = false RETURN count(p) as count",
        }
        
        # Requ√™te pour les prot√©ines isol√©es (sans relations SIMILAR)
        isolated_query = """
        MATCH (p:Protein)
        WHERE NOT (p)-[:SIMILAR]-()
        RETURN count(p) as count
        """
        
        # Requ√™te pour les statistiques de connectivit√©
        degree_query = """
        MATCH (p:Protein)
        OPTIONAL MATCH (p)-[r:SIMILAR]-()
        WITH p, count(r) as degree
        RETURN avg(degree) as avg_degree, 
               max(degree) as max_degree,
               min(degree) as min_degree,
               stdev(degree) as std_degree
        """
        
        # Requ√™te pour les statistiques de domaines
        domain_stats_query = """
        MATCH (d:Domain)<-[:HAS_DOMAIN]-(p:Protein)
        WITH d, count(p) as protein_count
        RETURN avg(protein_count) as avg_proteins_per_domain,
               max(protein_count) as max_proteins_per_domain,
               min(protein_count) as min_proteins_per_domain
        """
        
        try:
            stats = {}
            
            with self.driver.session() as session:
                # Compter les totaux
                for stat_name, query in queries.items():
                    result = session.run(query)
                    record = result.single()
                    stats[stat_name] = record["count"] if record else 0
                
                # Prot√©ines isol√©es
                result = session.run(isolated_query)
                record = result.single()
                stats["isolated_proteins"] = record["count"] if record else 0
                
                # Statistiques de degr√©
                result = session.run(degree_query)
                record = result.single()
                if record:
                    stats.update({
                        "avg_degree": round(record["avg_degree"] or 0, 2),
                        "max_degree": record["max_degree"] or 0,
                        "min_degree": record["min_degree"] or 0,
                        "std_degree": round(record["std_degree"] or 0, 2)
                    })
                
                
                # Statistiques de domaines
                result = session.run(domain_stats_query)
                record = result.single()
                if record:
                    stats.update({
                        "avg_proteins_per_domain": round(record["avg_proteins_per_domain"] or 0, 2),
                        "max_proteins_per_domain": record["max_proteins_per_domain"] or 0,
                        "min_proteins_per_domain": record["min_proteins_per_domain"] or 0
                    })
            
            print("‚úÖ Statistiques du graphe calcul√©es avec succ√®s")
            return stats
            
        except Exception as e:
            print(f"‚ùå Erreur lors du calcul des statistiques : {e}")
            return {}
    
    def find_proteins_by_similarity_threshold(self, min_jaccard: float = 0.3) -> List[Tuple[str, str, float]]:
        """
        Trouver des paires de prot√©ines avec une similarit√© au-dessus du seuil
        
        Args:
            min_jaccard: Seuil minimum du coefficient de Jaccard
            
        Returns:
            Liste de tuples (protein1_id, protein2_id, jaccard_score)
        """
        query = """
        MATCH (p1:Protein)-[r:SIMILAR]-(p2:Protein)
        WHERE r.jaccard_weight >= $min_jaccard AND elementId(p1) < elementId(p2)
        RETURN p1.uniprot_id as protein1, p2.uniprot_id as protein2, r.jaccard_weight as jaccard
        ORDER BY r.jaccard_weight DESC
        LIMIT 100
        """
        
        try:
            with self.driver.session() as session:
                result = session.run(query, min_jaccard=min_jaccard)
                pairs = [(record["protein1"], record["protein2"], record["jaccard"]) for record in result]
                print(f"‚úÖ {len(pairs)} paires de prot√©ines avec Jaccard ‚â• {min_jaccard}")
                return pairs
        except Exception as e:
            print(f"‚ùå Erreur lors de la recherche de prot√©ines similaires : {e}")
            return []
    
    def get_proteins_by_interpro_domain(self, domain_id: str) -> List[Dict[str, Any]]:
        """
        Obtenir toutes les prot√©ines contenant un domaine InterPro sp√©cifique
        
        Args:
            domain_id: Identifiant du domaine InterPro
            
        Returns:
            Liste de prot√©ines contenant le domaine
        """
        query = """
        MATCH (d:Domain {interpro_id: $domain_id})<-[:HAS_DOMAIN]-(p:Protein)
        RETURN p
        ORDER BY p.uniprot_id
        """
        
        try:
            with self.driver.session() as session:
                result = session.run(query, domain_id=domain_id)
                proteins = [dict(record["p"]) for record in result]
                print(f"‚úÖ {len(proteins)} prot√©ines trouv√©es avec le domaine {domain_id}")
                return proteins
        except Exception as e:
            print(f"‚ùå Erreur lors de la recherche par domaine : {e}")
            return []
    
    def export_neighborhood_for_visualization(self, protein_id: str, depth: int = 1) -> List[Dict[str, Any]]:
        """
        Exporter le voisinage au format Cytoscape.js.
        FILTRE AVANC√â : 
        1. Supprime les liens lat√©raux (Voisin <-> Voisin).
        2. Pour la Profondeur 2, ne garde QUE le lien avec le score Jaccard le plus √©lev√© (Best Match).
        """
        data = self.get_protein_neighborhood(protein_id, depth)
        
        if not data: return []
        
        elements = []
        center_id = data["center_protein"]["uniprot_id"]
        
        # --- 1. Identifier les voisins directs (Tier 1) ---
        tier1_ids = set()
        for rel in data["relationships"]:
            if rel["type"] == "SIMILAR":
                if rel["source"] == center_id: tier1_ids.add(rel["target"])
                elif rel["target"] == center_id: tier1_ids.add(rel["source"])
        
        # --- 2. Ajouter les N≈ìuds (Centre, Voisins, Domaines) ---        
        # Centre
        p = data["center_protein"]
        full_name = p.get("protein_names", ["N/A"])[0] if isinstance(p.get("protein_names"), list) and p.get("protein_names") else "N/A"
        elements.append({
            "group": "nodes",
            "data": { "id": p["uniprot_id"], "label": p["uniprot_id"], "full_name": full_name, "type": "center", "length": p.get("length", 0) }
        })
        
        # Voisins
        existing_nodes = {center_id}
        for n in data["neighbors"]:
            nid = n["uniprot_id"]
            if nid not in existing_nodes:
                full_name_neighbor = n.get("protein_names", ["N/A"])[0] if isinstance(n.get("protein_names"), list) and n.get("protein_names") else "N/A"
                
                # Type Distinction
                node_type = "neighbor_d1" if nid in tier1_ids else "neighbor_d2"

                elements.append({
                    "group": "nodes",
                    "data": { "id": nid, "label": nid, "full_name": full_name_neighbor, "type": node_type, "length": n.get("length", 0) }
                })
                existing_nodes.add(nid)
                
        # Domaines
        for d in data["domains"]:
            did = d["interpro_id"]
            dom_node_id = f"dom_{did}"
            elements.append({
                "group": "nodes",
                "data": { "id": dom_node_id, "label": did, "full_name": d.get("name", did), "type": "domain" }
            })

        # --- 3. TRAITEMENT DES AR√äTES ---
        
        final_edges = [] 
        best_d2_links = {}  # Structure: { 'ID_NOEUD_D2': { 'weight': 0.5, 'rel': relation_object } }

        for rel in data["relationships"]:
            original_source = rel["source"]
            original_target = rel["target"]
            rel_type = rel["type"]
            weight = rel.get("jaccard_weight", 0)
            
            # A. Domaines : On garde tout
            if rel_type == "HAS_DOMAIN":
                final_edges.append(rel)
                continue
            
            # B. Relations de similarit√©
            if rel_type == "SIMILAR":
                
                # Cas 1 : Connexion au Centre (Niveau 0 <-> Niveau 1) -> On garde TOUT
                if original_source == center_id or original_target == center_id:
                    final_edges.append(rel)
                    continue
                
                # Cas 2 : Lat√©ral (Niveau 1 <-> Niveau 1) -> On jette (comme avant)
                if original_source in tier1_ids and original_target in tier1_ids:
                    continue
                
                # Cas 3 : Connexion vers Niveau 2 (Niveau 1 <-> Niveau 2)
                # Identifier qui est le n≈ìud D2 dans la relation
                d2_node_id = None
                if original_source not in tier1_ids and original_source != center_id:
                    d2_node_id = original_source
                elif original_target not in tier1_ids and original_target != center_id:
                    d2_node_id = original_target
                
                if d2_node_id:
                    # Si on n'a pas encore de lien pour ce n≈ìud D2, ou si ce lien est meilleur
                    if d2_node_id not in best_d2_links:
                        best_d2_links[d2_node_id] = {"weight": weight, "rel": rel}
                    else:
                        if weight > best_d2_links[d2_node_id]["weight"]:
                            best_d2_links[d2_node_id] = {"weight": weight, "rel": rel}

        # Ajouter les meilleures ar√™tes D2 trouv√©es √† la liste finale
        for item in best_d2_links.values():
            final_edges.append(item["rel"])

        # --- 4. CR√âATION DES √âL√âMENTS CYTOSCAPE ---
        
        added_edges_keys = set()
        
        for i, rel in enumerate(final_edges):
            original_source = rel["source"]
            original_target = rel["target"]
            rel_type = rel["type"]
            
            viz_source = original_source
            viz_target = original_target
            
            # Formatage visuel (Direction des fl√®ches)
            if rel_type == "HAS_DOMAIN":
                viz_target = f"dom_{original_target}"
                edge_key = f"{viz_source}->{viz_target}"
            
            elif rel_type == "SIMILAR":
                # Cl√© unique pour √©viter doublons (normalement d√©j√† filtr√©s mais s√©curit√©)
                nodes = sorted([original_source, original_target])
                edge_key = f"{nodes[0]}-{nodes[1]}"
                if edge_key in added_edges_keys: continue
                
                # Orientation : Centre -> D1 -> D2
                if original_target == center_id:
                    viz_source = center_id
                    viz_target = original_source
                elif original_source == center_id:
                    viz_source = center_id
                    viz_target = original_target
                elif original_source in tier1_ids:
                    viz_source = original_source
                    viz_target = original_target
                elif original_target in tier1_ids:
                    viz_source = original_target
                    viz_target = original_source
                
                added_edges_keys.add(edge_key)

            edge_data = {
                "id": f"e_{i}", # ID unique
                "source": viz_source,
                "target": viz_target,
                "type": rel_type
            }
            
            if "jaccard_weight" in rel:
                edge_data["weight"] = round(rel["jaccard_weight"], 2)
                
            elements.append({
                "group": "edges",
                "data": edge_data
            })
            
        return elements


def demo_neo4j_queries():
    """D√©monstration des fonctionnalit√©s de requ√™te Neo4j"""
    
    # Initialiser le gestionnaire de requ√™tes
    query_manager = Neo4jProteinQueryManager()
    
    try:
        # Se connecter √† la base de donn√©es
        query_manager.connect()
        
        print("\n" + "="*60)
        print("D√âMONSTRATION DE REQU√äTES SUR LE GRAPHE DE PROT√âINES NEO4J")
        print("="*60)
        
        # 1. Statistiques du graphe
        print("\nüìä STATISTIQUES DU GRAPHE:")
        stats = query_manager.get_statistics()
        for key, value in stats.items():
            if key == 'top_connected_proteins':
                print(f"  {key}:")
                for protein_id, entry_name, degree in value:
                    print(f"    - {protein_id} ({entry_name}): {degree} connexions")
            else:
                print(f"  {key}: {value}")
        
        # 2. Recherche par identifiant
        print("\nüîç RECHERCHE PAR IDENTIFIANT:")
        # Obtenir un identifiant de prot√©ine exemple pour la d√©mo
        with query_manager.driver.session() as session:
            result = session.run("MATCH (p:Protein) RETURN p.uniprot_id LIMIT 1")
            record = result.single()
            if record:
                sample_id = record["p.uniprot_id"]
                protein = query_manager.search_by_identifier(sample_id)
                if protein:
                    print(f"  Trouv√©: {protein.get('entry_name', 'N/A')} (Longueur: {protein.get('length', 'N/A')})")
        
        # 3. Afficher le voisinage
        print("\nüï∏Ô∏è VOISINAGE DE LA PROT√âINE:")
        if 'sample_id' in locals():
            neighborhood = query_manager.get_protein_neighborhood(sample_id, depth=1)
            if neighborhood:
                print(f"  Centre: {neighborhood['center_protein'].get('entry_name', 'N/A')}")
                print(f"  Voisins: {len(neighborhood['neighbors'])}")
                print(f"  Domaines: {len(neighborhood['domains'])}")
                print(f"  Relations de similarit√©: {len(neighborhood['relationships'])}")
        
        # 4. Prot√©ines isol√©es
        print(f"\nüèùÔ∏è ANALYSE DE L'ISOLATION:")
        isolated_count = stats.get('isolated_proteins', 0)
        total_count = stats.get('total_proteins', 0)
        if total_count > 0:
            isolation_rate = (isolated_count / total_count) * 100
            print(f"  Prot√©ines isol√©es: {isolated_count} ({isolation_rate:.1f}%)")
            print(f"  Prot√©ines connect√©es: {total_count - isolated_count} ({100 - isolation_rate:.1f}%)")
        
        # 5. Paires √† haute similarit√©
        print("\nü§ù PAIRES √Ä HAUTE SIMILARIT√â:")
        similar_pairs = query_manager.find_proteins_by_similarity_threshold(0.5)
        for i, (p1, p2, jaccard) in enumerate(similar_pairs[:3]):
            print(f"  {i+1}. {p1} ‚Üî {p2} (Jaccard: {jaccard:.3f})")
        
    except Exception as e:
        print(f"‚ùå Erreur de d√©mo : {e}")
    finally:
        query_manager.disconnect()


if __name__ == "__main__":
    demo_neo4j_queries()